import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import confusion_matrix, recall_score, f1_score, precision_score
from pandas import DataFrame
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
from graphviz import Source

# Función para dividir el conjunto de datos en entrenamiento, validación y prueba
def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):
    strat = df[stratify] if stratify else None
    train_set, test_set = train_test_split(
        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)
    strat = test_set[stratify] if stratify else None
    val_set, test_set = train_test_split(
        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)
    return (train_set, val_set, test_set)

# Función para separar las etiquetas del conjunto de datos
def remove_labels(df, label_name):
    X = df.drop(label_name, axis=1)
    y = df[label_name].copy()
    return (X, y)

# Función para evaluar los resultados
def evaluate_result(y_pred, y, y_prep_pred, y_prep, metric):
    print(metric.__name__, "WITHOUT preparation:", metric(y, y_pred, average='weighted'))
    print(metric.__name__, "WITH preparation:", metric(y_prep, y_prep_pred, average='weighted'))

# Lectura del conjunto de datos
base_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(base_dir, 'datasets', 'obesidad.csv')
df = pd.read_csv(csv_path)

# Visualización básica del conjunto de datos
df.info()
print(df['Weight'].value_counts())

# Transformaciones para calcular correlaciones
X = df.copy()
X['Weight'] = X['Weight'].factorize()[0]

for col in X.select_dtypes(include=["object", "category"]).columns:
    if X[col].nunique() == 2:
        X[col] = X[col].map({"yes": 1, "no": 0})
    else:
        X = pd.get_dummies(X, columns=[col], drop_first=True)

X.fillna(0, inplace=True)
X_numeric = X.select_dtypes(include=["number"])

if "Weight" in X_numeric.columns:
    print(X_numeric.corr()["Weight"].sort_values(ascending=False))
else:
    print("La columna 'Weight' no está presente en las columnas numéricas.")

# División del conjunto de datos
train_set, val_set, test_set = train_val_test_split(X)
X_train, y_train = remove_labels(train_set, 'Weight')
X_val, y_val = remove_labels(val_set, 'Weight')
X_test, y_test = remove_labels(test_set, 'Weight')

# Escalado del conjunto de datos
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_val_scaled = scaler.transform(X_val)

X_train_scaled = DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)

# Entrenamiento de árboles de decisión
MAX_DEPTH = 20
clf_tree = DecisionTreeClassifier(max_depth=MAX_DEPTH, random_state=42)
clf_tree.fit(X_train, y_train)

clf_tree_scaled = DecisionTreeClassifier(max_depth=MAX_DEPTH, random_state=42)
clf_tree_scaled.fit(X_train_scaled, y_train)

# Evaluación del modelo
y_train_pred = clf_tree.predict(X_train)
y_train_prep_pred = clf_tree_scaled.predict(X_train_scaled)
evaluate_result(y_train_pred, y_train, y_train_prep_pred, y_train, f1_score)

y_pred = clf_tree.predict(X_val)
y_prep_pred = clf_tree_scaled.predict(X_val_scaled)
evaluate_result(y_pred, y_val, y_prep_pred, y_val, f1_score)

# Visualización del límite de decisión
X_train_reduced = X_train[['Height', 'Age']]
clf_tree_reduced = DecisionTreeClassifier(max_depth=2, random_state=42)
clf_tree_reduced.fit(X_train_reduced, y_train)

def plot_decision_boundary(clf, X, y, plot_training=True, resolution=1000):
    mins = X.min(axis=0) - 1
    maxs = X.max(axis=0) + 1
    x1, x2 = np.meshgrid(
        np.linspace(mins[0], maxs[0], resolution),
        np.linspace(mins[1], maxs[1], resolution))
    X_new = np.c_[x1.ravel(), x2.ravel()]
    y_pred = clf.predict(X_new).reshape(x1.shape)
    custom_cmap = ListedColormap(['#fafab0', '#9898ff', '#a0faa0'])
    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)
    if plot_training:
        plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], c='yellow', label="normal")
        plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], c='blue', label="adware")
        plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], c='green', label="malware")
    plt.xlabel('Height', fontsize=14)
    plt.ylabel('Age', fontsize=14)
    plt.legend()

plt.figure(figsize=(12, 6))
plot_decision_boundary(clf_tree_reduced, X_train_reduced.values, y_train)
plt.show()

# Exportación y visualización del árbol de decisión
class_names = [str(cls) for cls in clf_tree_reduced.classes_]
export_graphviz(
    clf_tree_reduced,
    out_file="android_malware.dot",
    feature_names=X_train_reduced.columns,
    class_names=class_names,
    rounded=True,
    filled=True
)
Source.from_file("android_malware.dot").view()




